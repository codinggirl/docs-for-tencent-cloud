## 消费异常如何排查？

- 在 CKafka 控制台监控页面查看流量监控情况，观察是否存在波峰，升级实例大小解决。

  ![](https://main.qcloudimg.com/raw/a5ef5e5067c265073ef8cb0c07960461.png)

- 查看消费分组是否超过数量。

- 如果因为网络频繁 rebalance，建议调整客户端超时时间。

- 是否拉取过期的 offset，消息过期会被删除，如果用过期 offset 拉取会失败。

## 生产一段时间后发现持续性错误如何排查？

- 查看是否流量流控，在监控页面上查询是否有波峰，升级实例大小解决。
- 查看是否容量流控，在监控页面上查询实例的磁盘容量，升级实例大小或者修改数据保存时间。

## 剩余的未消费消息的条数是如何计算的？

计算方式为：未消费消息数量 = 最大的offset - 提交的 offset。如下图：

![img](https://main.qcloudimg.com/raw/05c88d97f36784e5f83c08b24e229265.png)



## 过期消息为何没有及时被删除？

kafka的消息删除机制会导致某些业务场景出现过期消息没有及时删除的情况，如果对机制不了解容易产生疑惑，具体问题如下：

这里分区0和分区7的消息时间戳存在明显差距，分区0的过期消息没有被及时删除，如下图所示：
- 分区为0：
![](https://main.qcloudimg.com/raw/15259a044edd174cbe609a9a95e43ea2.png)
- 分区为7：
![](https://main.qcloudimg.com/raw/bda384e0ed20e043f9416481e6d6d2a5.png)

**Kafka消息删除机制**

Kafka数据存储是以 Topic、分区、数据段三个维度实际落盘存储的，消息数据删除的条件如下：

1. 消息数据根据保留时间进行删除，删除是以数据段为单位的。
2. 每个数据段当前是设置为1GB大小，达到1GB后滚动生成新的数据段。
3. 数据段内的所有消息都过期才会删除该数据段。
4. 如果数据段内有一行消息在保留时间内，即例如段文件的最后一行是在保留时间内，这个段文件就不会被删除。

由于某些原因导致消息写入有倾斜，数据写入集中在某些分区，例如分区7，某些分区数据很少，例如分区0。此时分区0的数据段大小未达到1GB，没发生滚动，但整个段内有数据在保留时间内，所以分区0中的消息就不会被删除。



## 是否支持自动调整消息保留时间？

CKafka 支持添加动态消息保留策略功能，设置数据动态保留策略后，当磁盘空间使用率到达一定的比例后，会自动向前过期一定比例的数据，避免遇到用户消息猛增的情况，磁盘空间满了之后，则无法正常生产和消费。具体操作方式参考 [添加动态消息保留策略](https://cloud.tencent.com/document/product/597/53850)。
